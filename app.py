import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
from pdf2image import convert_from_bytes
from PIL import Image
import io
import logging

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def set_page_config():
    st.set_page_config(
        page_title="ØªÙ…ÙˆÙŠÙ‡ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø§Ù„Ø°ÙƒÙŠ",
        page_icon="ğŸ­",
        layout="wide"
    )
    
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap');
    
    * {
        font-family: 'Tajawal', sans-serif;
    }
    
    .stApp {
        background: linear-gradient(120deg, #E3F2FD 0%, #BBDEFB 100%);
    }
    
    .main {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
    }
    
    .stButton>button {
        background: linear-gradient(45deg, #2196F3, #0039CB);
        color: white;
        padding: 0.8rem 2rem;
        border-radius: 10px;
        border: none;
        font-weight: bold;
        width: 100%;
        transition: transform 0.3s ease;
    }
    
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(33, 150, 243, 0.3);
    }
    </style>
    """, unsafe_allow_html=True)

class FaceDetector:
    def __init__(self):
        # Ø¥Ø¹Ø¯Ø§Ø¯ MediaPipe Face Detection Ù…Ø¹ Ù…Ø¹Ø§ÙŠÙŠØ± ØµØ§Ø±Ù…Ø©
        self.mp_face = mp.solutions.face_detection.FaceDetection(
            model_selection=1,
            min_detection_confidence=0.7  # Ø²ÙŠØ§Ø¯Ø© Ø¯Ù‚Ø© Ø§Ù„ÙƒØ´Ù
        )
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ MediaPipe Face Mesh Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ÙˆØ¬ÙˆÙ‡
        self.mp_face_mesh = mp.solutions.face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=10,
            min_detection_confidence=0.7
        )

    def is_valid_face(self, box: list, image_shape: tuple) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ù…ÙƒØªØ´Ù"""
        x, y, w, h = box
        height, width = image_shape[:2]
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø³Ø¨Ø© Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ÙˆØ¬Ù‡
        aspect_ratio = w / h
        if not (0.6 <= aspect_ratio <= 1.4):  # Ù†Ø³Ø¨Ø© Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ø¨Ø´Ø±ÙŠ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©
            return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„ØµÙˆØ±Ø©
        face_area = w * h
        image_area = width * height
        face_area_ratio = face_area / image_area
        
        if face_area_ratio < 0.01 or face_area_ratio > 0.4:
            return False
            
        return True

    def detect_faces(self, image: np.ndarray) -> list:
        faces = []
        height, width = image.shape[:2]
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… MediaPipe
        results = self.mp_face.process(rgb_image)
        
        if results.detections:
            for detection in results.detections:
                if detection.score[0] > 0.7:  # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©
                    bbox = detection.location_data.relative_bounding_box
                    x = max(0, int(bbox.xmin * width))
                    y = max(0, int(bbox.ymin * height))
                    w = min(int(bbox.width * width), width - x)
                    h = min(int(bbox.height * height), height - y)
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙˆØ¬Ù‡
                    if self.is_valid_face([x, y, w, h], image.shape):
                        # ØªÙˆØ³ÙŠØ¹ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ÙˆØ¬Ù‡ Ù‚Ù„ÙŠÙ„Ø§Ù‹
                        padding_x = int(w * 0.1)
                        padding_y = int(h * 0.1)
                        x = max(0, x - padding_x)
                        y = max(0, y - padding_y)
                        w = min(w + 2*padding_x, width - x)
                        h = min(h + 2*padding_y, height - y)
                        
                        faces.append({
                            'box': [x, y, w, h],
                            'confidence': float(detection.score[0])
                        })
        
        return faces

class FaceBlurProcessor:
    def __init__(self):
        self.detector = FaceDetector()
    
    def apply_blur(self, image: np.ndarray, box: list) -> np.ndarray:
        x, y, w, h = box
        center = (x + w//2, y + h//2)
        radius = int(max(w, h) * 0.9)  # Ø²ÙŠØ§Ø¯Ø© Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªÙ…ÙˆÙŠÙ‡
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ù†Ø§Ø¹ Ø¯Ø§Ø¦Ø±ÙŠ Ù…ØªØ¯Ø±Ø¬
        mask = np.zeros(image.shape[:2], dtype=np.float32)
        cv2.circle(mask, center, radius, 1.0, -1)
        mask = cv2.GaussianBlur(mask, (99, 99), 30)
        
        # ØªØ·Ø¨ÙŠÙ‚ ØªÙ…ÙˆÙŠÙ‡ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹
        blurred = cv2.GaussianBlur(image, (99, 99), 30)
        blurred = cv2.GaussianBlur(blurred, (99, 99), 30)  # ØªÙ…ÙˆÙŠÙ‡ Ù…Ø¶Ø§Ø¹Ù
        
        # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ±
        mask = np.expand_dims(mask, -1)
        result = image * (1 - mask) + blurred * mask
        
        return result.astype(np.uint8)
    
    def process_image(self, image: Image.Image) -> Image.Image:
        try:
            img = np.array(image)
            faces = self.detector.detect_faces(img)
            
            if not faces:
                return image
            
            for face in faces:
                img = self.apply_blur(img, face['box'])
            
            return Image.fromarray(img)
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
            raise

def main():
    set_page_config()
    
    st.title("ğŸ­ ØªÙ…ÙˆÙŠÙ‡ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø§Ù„Ø°ÙƒÙŠ")
    st.markdown("""
    <p style='font-size: 1.2rem; text-align: center;'>
        Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ÙˆØ¬ÙˆÙ‡ ÙˆØªÙ…ÙˆÙŠÙ‡Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    </p>
    """, unsafe_allow_html=True)
    
    processor = FaceBlurProcessor()
    
    uploaded_file = st.file_uploader(
        "Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø£Ùˆ Ù…Ù„Ù PDF",
        type=["jpg", "jpeg", "png", "pdf"]
    )
    
    if uploaded_file:
        try:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©..."):
                if uploaded_file.type == "application/pdf":
                    images = convert_from_bytes(uploaded_file.read())
                    for idx, img in enumerate(images, 1):
                        processed = processor.process_image(img)
                        st.image(processed, caption=f"Ø§Ù„ØµÙØ­Ø© {idx}", use_column_width=True)
                        
                        buf = io.BytesIO()
                        processed.save(buf, format="PNG")
                        st.download_button(
                            f"ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© {idx}",
                            buf.getvalue(),
                            f"processed_page_{idx}.png",
                            "image/png"
                        )
                else:
                    image = Image.open(uploaded_file)
                    processed = processor.process_image(image)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
                    with col2:
                        st.image(processed, caption="Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", use_column_width=True)
                    
                    buf = io.BytesIO()
                    processed.save(buf, format="PNG")
                    st.download_button(
                        "ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
                        buf.getvalue(),
                        "processed_image.png",
                        "image/png"
                    )
            
            st.success("ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­!")
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")

if __name__ == "__main__":
    main()
